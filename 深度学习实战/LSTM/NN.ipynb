{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\Astock\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stock = pd.read_csv('feature_stock1.csv')\n",
    "features_stock2 = pd.read_csv('feature_stock2.csv')\n",
    "features_stock = features_stock2.merge(features_stock, on=['trade_date', 'ts_code'], how='left')\n",
    "del features_stock2\n",
    "feature_index = pd.read_csv('feature_index.csv')\n",
    "features_stock = features_stock.merge(feature_index[['trade_date', 'rate_1', 'rate_2', 'rate_3', \n",
    "                                                     'rate', ]], on='trade_date', how='left')\n",
    "del feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = ['open_transform', 'close_transform', 'high_transform', 'low_transform',\n",
    "                   'open_transform_shift_1', 'open_transform_shift_2', 'close_transform_shift_1',\n",
    "                   'close_transform_shift_2', 'high_transform_shift_1', 'high_transform_shift_2',\n",
    "                   'low_transform_shift_1', 'low_transform_shift_2', 'rate', 'rate_1', 'rate_2', 'rate_3',\n",
    "                   'open_transform_3', 'close_3', 'turnover_rate',\n",
    "                   'pingjun_3', 'turnover_rate_shift_1', 'turnover_rate_shift_2', 'weekday',\n",
    "                   'zhenfu', 'zhenfu_shift_1', 'zhenfu_shift_2', 'high_10', 'low_10', 'high_20', 'low_20'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stock = features_stock.rename(columns={'ts_code':'name', 'trade_date':'day', 'close':'close_price'})\n",
    "features = features_stock\n",
    "features = features.dropna().reset_index(drop=True)\n",
    "features['label'] = ((features['next_close'] / features['close_price'] - 1) > 0)\n",
    "features['rate_stock'] = (features['next_close'] / features['close_price'] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['label'] = features['label'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date_min = 20170101\n",
    "train_date_max = 20190101\n",
    "\n",
    "val_date_min = 20190102\n",
    "val_date_max = 20200101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features\n",
    "idx = (df['day']>=train_date_min) & (df['day']<=train_date_max)\n",
    "for tmp_col in feature_col:\n",
    "    max_ = np.percentile(df[idx][tmp_col], 99.99)\n",
    "    df.loc[df[tmp_col]>max_, tmp_col] = max_\n",
    "    min_ = np.percentile(df[idx][tmp_col], 0.01)\n",
    "    df.loc[df[tmp_col]<min_, tmp_col] = min_\n",
    "    \n",
    "    df[tmp_col] = (df[tmp_col] - df[idx][tmp_col].mean()) / (df[idx][tmp_col].std() + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取class的天和time\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "trn_time_start = []  # 起始时间\n",
    "val_time_start = []  # 测试起始时间\n",
    "classes = []\n",
    "class_dict = dict()\n",
    "data_len = 10\n",
    "num = -1\n",
    "\n",
    "df_test_all = []\n",
    "\n",
    "for i, g in tqdm(df.groupby(['name'])):\n",
    "    num = num + 1\n",
    "    class_dict[num] = i\n",
    "    classes.append(num)\n",
    "    \n",
    "    g = g.reset_index(drop=True)\n",
    "    g = g.sort_values(['day'], ascending=[True]).reset_index(drop=True)\n",
    "    g_trn = g[(g['day'] >= train_date_min) & (g['day'] <= train_date_max)].reset_index(drop=True)\n",
    "    \n",
    "    if len(g_trn) < data_len:\n",
    "        train_data.append([])\n",
    "        train_label.append([])\n",
    "        trn_time_start.append([])\n",
    "#         print('%s has no training data' % i)\n",
    "    else:\n",
    "\n",
    "        train_data.append(g_trn[feature_col].values)\n",
    "        train_label.append(g_trn['label'].values)\n",
    "        trn_time_start.append(list(range(len(g_trn) - data_len + 1)))\n",
    "    \n",
    "    idx = g[(g['day'] >= val_date_min) & (g['day'] <= val_date_max)].index  \n",
    "    if len(idx) < data_len:\n",
    "        val_time_start.append([])\n",
    "        test_data.append([])\n",
    "        test_label.append([])\n",
    "\n",
    "    else:\n",
    "        st = max(idx[0] - data_len + 1, 0)\n",
    "        et = idx[-1]\n",
    "        g_test = g.loc[st:et]\n",
    "        val_time_start.append(list(range(len(g_test) - data_len + 1)))\n",
    "        test_data.append(g_test[feature_col].values)\n",
    "        test_label.append(g_test['label'].values)\n",
    "        df_test_all.append(g.loc[st + data_len - 1:et][['name', 'day', 'label', 'next_close', 'close_price', 'is_limit']])\n",
    "df_test_all = pd.concat(df_test_all)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练idx\n",
    "idxs = []\n",
    "for i in range(len(classes)):\n",
    "    tmp_t = trn_time_start[i]\n",
    "    tmp_t = np.reshape(tmp_t, (-1, 1))\n",
    "    if len(trn_time_start[i]) <= 0:\n",
    "        continue\n",
    "    tmp_c = np.ones((len(trn_time_start[i]), 1)) * classes[i]\n",
    "    idxs.append(np.concatenate([tmp_c, tmp_t], axis=1))\n",
    "    \n",
    "\n",
    "idxs = np.concatenate(idxs, axis=0)\n",
    "df_sample_trn = pd.DataFrame(idxs, columns=['id', 'st'])\n",
    "df_sample_trn['id'] = df_sample_trn['id'].astype(int)\n",
    "df_sample_trn['st'] = df_sample_trn['st'].astype(int)\n",
    "\n",
    "idxs = []\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    test_ = test_data[i]\n",
    "    tmp_t = val_time_start[i]\n",
    "    tmp_t = np.reshape(tmp_t, (-1, 1))\n",
    "    if len(val_time_start[i]) <= 0:\n",
    "        continue\n",
    "    tmp_c = np.ones((len(val_time_start[i]), 1)) * classes[i]\n",
    "    idxs.append(np.concatenate([tmp_c, tmp_t], axis=1))\n",
    "\n",
    "    assert len(test_)-data_len+1 == len(val_time_start[i])\n",
    "\n",
    "idxs = np.concatenate(idxs, axis=0)\n",
    "df_sample_test = pd.DataFrame(idxs, columns=['id', 'st'])\n",
    "df_sample_test['id'] = df_sample_test['id'].astype(int)\n",
    "df_sample_test['st'] = df_sample_test['st'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(lstm, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(in_dim, 64, 1, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(128, 128, 1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.lstm1(x)\n",
    "        x, (_, _) = self.lstm2(x)\n",
    "        #         print(x.shape)\n",
    "        x = self.fc(x[:, -1, :].reshape((x.size(0), -1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_dataloader, val_dataloader):\n",
    "    model.train()\n",
    "    f1_meter, loss_meter, it_count = 0, 0, 0\n",
    "    tq = tqdm(range(len(train_dataloader)))\n",
    "    for i, (inputs, target) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        output = model(inputs)\n",
    "        output = torch.sigmoid(output)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter += loss.item()\n",
    "        it_count += 1\n",
    "        tq.set_description('batch: %d, loss: %.3f' % (i, loss.item()))\n",
    "        tq.update(1)\n",
    "    tq.close()\n",
    "    return loss_meter / it_count\n",
    "\n",
    "def val_epoch(model, criterion, val_dataloade):\n",
    "    model.eval()\n",
    "    loss_meter, it_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            label_all = torch.FloatTensor().cuda()\n",
    "            pred_all = torch.FloatTensor().cuda()\n",
    "        else:\n",
    "            label_all = torch.FloatTensor()\n",
    "            pred_all = torch.FloatTensor()\n",
    "\n",
    "        num = 0\n",
    "        for inputs, target in tqdm(val_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(inputs)\n",
    "            output = torch.sigmoid(output)\n",
    "            it_count += 1\n",
    "            label_all = torch.cat((label_all, target), 0)\n",
    "            pred_all = torch.cat((pred_all, output), 0)\n",
    "\n",
    "        output = pred_all.cpu().detach().numpy()\n",
    "        target = label_all.cpu().detach().numpy()\n",
    "        \n",
    "        loss = np.mean(target * np.log(output) + (1-target) * np.log((1-output)))\n",
    "#         loss = np.mean(np.abs(output - target))\n",
    "\n",
    "    return loss, target, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df_sample, data, label, data_len, train=True):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.df_sample = df_sample.values\n",
    "        self.data_len = data_len\n",
    "        self.label = label\n",
    "        self.data = data\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        idx = int(self.df_sample[index][0])\n",
    "        st = int(self.df_sample[index][1])\n",
    "        tmp_data = self.data[idx]\n",
    "        tmp_label = self.label[idx]\n",
    "        x = tmp_data[st:st + self.data_len]\n",
    "        y = tmp_label[st + self.data_len-1]\n",
    "        y = np.reshape(y, (-1))\n",
    "        x = np.reshape(x, (self.data_len, len(feature_col)))\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "label_col = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchannels = len(feature_col)\n",
    "model = lstm(inchannels)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "train_dataset = MyDataset(df_sample_trn, train_data, train_label, data_len,)\n",
    "val_dataset = MyDataset(df_sample_test, test_data, test_label, data_len,)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1024, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 1\n",
    "for i in range(max_epoch):\n",
    "    trn_loss = train_epoch(model, optimizer, criterion, train_dataloader, val_dataloader)\n",
    "    model_save_dir = 'model_lstm_' + str(i+1) + '.pth'\n",
    "    torch.save(model.state_dict(), model_save_dir)\n",
    "    print(trn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, target, output = val_epoch(model, criterion, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list = sorted(df_test_all['day'].unique())\n",
    "oof = output > 0.5\n",
    "print('acc: %.4f' % metrics.accuracy_score(target, oof))\n",
    "print(metrics.confusion_matrix(target, oof))\n",
    "\n",
    "oof = output > 0.6\n",
    "acc2 = np.sum(oof * target) / np.sum(oof)\n",
    "print('precision: %.4f' % acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_df = df_test_all.copy()\n",
    "buy_df['pred'] = oof\n",
    "buy_df['prob'] = output\n",
    "idx = (buy_df['is_limit']==False) & (buy_df['pred']==1) #&(buy_df['close_transform']<1.15)\n",
    "buy_df = buy_df[idx]\n",
    "buy_df['next_open'] = buy_df['next_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import Account\n",
    "reload(Account)\n",
    "money_init = 100000\n",
    "account = Account.Account(money_init)\n",
    "account.BackTest(buy_df, sorted(day_list), buy_price='close_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_profit = (account.market_value - money_init) / money_init\n",
    "win_rate = account.victory / (account.victory + account.defeat)\n",
    "print('账户盈利情况:%.4f' % account_profit)\n",
    "print('交易胜率:%.4f' % win_rate)\n",
    "print('最大回撤率:%.4f' % account.max_retracement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(account.market_value_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "770541d2acddad07702d45b2ec947abc2ba514fe3889bffd6df0b0670498143a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
